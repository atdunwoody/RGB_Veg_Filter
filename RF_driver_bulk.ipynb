{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Tiled_Classification_RF as TCRF\n",
    "import os, tempfile\n",
    "from osgeo import gdal, ogr, gdal_array # I/O image data\n",
    "import numpy as np # math and array handling\n",
    "import matplotlib.pyplot as plt # plot figures\n",
    "from sklearn.ensemble import RandomForestClassifier # classifier\n",
    "import pandas as pd # handling large data as table sheets\n",
    "import geopandas as gpd # handling large data as shapefiles\n",
    "from sklearn.metrics import classification_report, accuracy_score,confusion_matrix  # calculating measures for accuracy assessment\n",
    "import datetime\n",
    "from xgboost import XGBClassifier\n",
    "# Tell GDAL to throw Python exceptions, and register all drivers\n",
    "gdal.UseExceptions()\n",
    "gdal.AllRegister()\n",
    "from GIStools.GIStools import preprocess_SfM_inputs\n",
    "from GIStools.Stitch_Rasters import stitch_rasters\n",
    "from GIStools.Grid_Creation import create_grid\n",
    "from GIStools.Raster_Matching import pad_rasters_to_largest\n",
    "from input_parameters import InputParameters\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------Required User Defined Inputs-------------------#\n",
    "params = InputParameters()\n",
    "\n",
    "DEM_path = params.DEM_path\n",
    "ortho_path = params.ortho_path\n",
    "output_folder = params.output_folder\n",
    "model_path = params.model_path\n",
    "training_path = params.training_path\n",
    "validation_path = params.validation_path\n",
    "attribute = params.attribute\n",
    "validation_path_2 = params.validation_path_2\n",
    "grid_ids = params.grid_ids\n",
    "grid_path = params.grid_path\n",
    "process_training_only = params.process_training_only\n",
    "est = params.est\n",
    "n_cores = params.n_cores\n",
    "gradient_boosting = params.gradient_boosting\n",
    "verbose = params.verbose\n",
    "stitch = params.stitch\n",
    "\n",
    "#--------------------Input Preparation-----------------------------#\n",
    "#Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "#List of grid-clipped images to classify and associated id values\n",
    "in_dir = os.path.join(output_folder, 'RF_Tiled_Inputs')\n",
    "#output folder for list of img_path_list grid-clipped classified images\n",
    "\n",
    "# directory, where the classification image should be saved:\n",
    "results_folder = os.path.join(output_folder, 'RF_Results')\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "classification_image = os.path.join(results_folder, 'Classified_Training_Image.tif')\n",
    "classified_tile_folder = os.path.join(results_folder, 'Classified_Tiles')\n",
    "if not os.path.exists(classified_tile_folder) and process_training_only == False:\n",
    "    os.makedirs(os.path.join(classified_tile_folder))\n",
    "\n",
    "results_txt = os.path.join(output_folder, 'Results_Summary.txt') # directory, where the all meta results will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================== Preprocessing ====================#\n",
    "    #Create grid cells to process large rasters in chunks. \n",
    "#Each grid cell is the size of the extent training and validation shapefiles\n",
    "if grid_path is None:\n",
    "    train_val_grid_id, grid_path, _ = create_grid([training_path,validation_path], DEM_path, in_dir)\n",
    "    train_tile_path = os.path.join(in_dir, f'stacked_bands_tile_input_{train_val_grid_id}.tif') # grid-clipped-image containing the training data\n",
    "    if process_training_only: #preprocess_function will now only process the training tile\n",
    "        grid_ids.append(train_val_grid_id)\n",
    "        params.grid_ids = grid_ids\n",
    "    print('Training Grid ID: {}'.format(train_val_grid_id)) \n",
    "else:\n",
    "    grid = gpd.read_file(grid_path)\n",
    "    params.grid_ids = grid['ID'].values.tolist() if grid_ids is None else grid_ids\n",
    "    print('Grid IDs: {}'.format(grid_ids))  \n",
    "#Bands output from preprocess function: Roughness, R, G, B, Saturation, Excessive Green Index\n",
    "grid_ids, input_dict = preprocess_SfM_inputs(grid_path, ortho_path, DEM_path, params.grid_ids, in_dir, verbose=verbose) #Prepare input stacked rasters for random forest classification\n",
    "print('Grid IDs to process: {}'.format(grid_ids))\n",
    "\n",
    "img_path_list, id_values = TCRF.find_files(in_dir) # list of all grid-clipped images to classify and associated id values\n",
    "attribute_names = TCRF.print_attributes(training_path) # print the attributes in the training shapefile\n",
    "#===========================Main Classification Loop===========================#\n",
    "\n",
    "TCRF.print_header_params(results_txt, params) # print the header for the results text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Function to process a single tile\n",
    "def process_tile(img_path, id_value, rf_model, output_dir, results_file):\n",
    "    print(f\"Processing {img_path}, ID value: {id_value}\")\n",
    "    current_tile, current_tile_3Darray = TCRF.extract_image_data(img_path, results_file, log=False)\n",
    "    current_tile_2Darray = TCRF.flatten_raster_bands(current_tile_3Darray)\n",
    "    current_class_prediction = TCRF.predict_classification(rf_model, current_tile_2Darray, current_tile_3Darray)\n",
    "    current_masked_prediction = TCRF.reshape_and_mask_prediction(current_class_prediction, current_tile_3Darray)\n",
    "    output_file = output_dir / f\"Classified_Tile_{id_value}.tif\"\n",
    "    TCRF.save_classification_image(output_file, current_tile, current_tile_3Darray, current_masked_prediction)\n",
    "    print(f'Tile saved to: {output_file}')\n",
    "    # Clean up\n",
    "    del current_class_prediction, current_masked_prediction, current_tile_3Darray, current_tile_2Darray\n",
    "\n",
    "# Function to process all tiles in bulk using multiprocessing\n",
    "def bulk_process(tiles, rf_model, classified_tile_folder, results_txt):\n",
    "    with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "        pool.starmap(process_tile, [(img_path, id_value, rf_model, classified_tile_folder, results_txt) for img_path, id_value in tiles])\n",
    "\n",
    "\n",
    "# Load the saved model from the path\n",
    "model_path = r\"Y:\\ATD\\GIS\\East_Troublesome\\RF Vegetation Filtering\\LM2\\LM2_2023___070923 - XGB Saved Model\\RF_Model.joblib\"\n",
    "model = joblib.load(model_path)  # Load the model\n",
    "in_dir = r\"Y:\\ATD\\GIS\\East_Troublesome\\RF Vegetation Filtering\\LM2 - 081222 Full Run\\RF_Tiled_Inputs\"\n",
    "classified_tile_folder_path = Path(classified_tile_folder)\n",
    "img_path_list, id_values = TCRF.find_files(in_dir)  # Get the list of tiles to process\n",
    "tiles = zip(img_path_list, id_values)\n",
    "bulk_process(tiles, model, classified_tile_folder_path, results_txt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIStools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
