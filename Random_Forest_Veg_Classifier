import rasterio
from rasterio.windows import Window
from rasterio.mask import mask
import geopandas as gpd

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder

import numpy as np
import os
from osgeo import gdal
from joblib import Parallel, delayed


def read_raster(file_path):
    # Open the raster file and return the DatasetReader object and its transform
    src = rasterio.open(file_path)
    return src, src.transform

def extract_features(rasters, shapefile):
    features = []
    labels = []
    raster_outputs = []

    for src, transform in rasters:
        raster = src.read()  # Read the raster data as a NumPy array here
        for index, row in shapefile.iterrows():
            out_image, out_transform = mask(src, [row['geometry']], crop=True)
            out_image = out_image.reshape(-1)
            features.append(out_image)
            labels.append(row['MC'])
            raster_outputs.append(out_image)

    # Close each raster file after processing
    for src, _ in rasters:
        src.close()

    return features, labels, raster_outputs

def train_RF(raster_paths, shapefile_path):
    # Read rasters and shapefile
    rasters = [read_raster(path) for path in raster_paths]
    shapefile = gpd.read_file(shapefile_path)

    # Extract features and raster outputs
    features, labels, _ = extract_features(rasters, shapefile)

    # Data Preparation
    # Reshape features
    max_length = max([len(feature) for feature in features])
    features = [np.pad(feature, (0, max_length - len(feature))) if len(feature) < max_length else feature[:max_length] for feature in features]

    # Encode labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)
    print(labels[:10], encoded_labels[:10])
    # Split Data
    X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)

    # Random Forest Training
    parameter_distributions = {
        'n_estimators': [100, 200, 300, 400, 500],
        'max_depth': [None, 10, 20, 30, 40, 50],
        'min_samples_split': [2, 5, 10, 20],
        'min_samples_leaf': [1, 2, 4, 10]
    }

    rf = RandomForestClassifier(random_state=42)
    random_search = RandomizedSearchCV(estimator=rf, param_distributions=parameter_distributions, 
                                       n_iter=30, cv=4, n_jobs=-1, verbose=2, random_state=42)
    random_search.fit(X_train, y_train)

    # Model Evaluation
    predictions = random_search.predict(X_test)
    print(classification_report(y_test, predictions))

    # Output the best parameters and performance metrics
    best_estimator = random_search.best_estimator_
    best_score = random_search.best_score_
    performance_metrics = random_search.cv_results_

    print("Best Estimator:", best_estimator)
    print("Best Score:", best_score)
    max_length = max([len(feature) for feature in features])
    
    return best_estimator, best_score, performance_metrics, max_length

def read_and_stack_rasters(raster_paths):
    """ Read and stack multiple rasters into a single array. """
    with rasterio.open(raster_paths[0]) as src0:
        meta = src0.meta.copy()
        stacked_array = np.zeros((len(raster_paths), src0.height, src0.width), dtype=src0.dtypes[0])

    for i, path in enumerate(raster_paths):
        with rasterio.open(path) as src:
            stacked_array[i, :, :] = src.read(1)

    meta.update(count=len(raster_paths))
    return stacked_array, meta

def reshape_for_prediction(tile_data, max_length):
    """ Reshape and pad the tile data for prediction. Adjust this logic as per your classifier's input requirements. """
    reshaped = tile_data.reshape(-1)
    if len(reshaped) < max_length:
        return np.pad(reshaped, (0, max_length - len(reshaped)))
    else:
        return reshaped[:max_length]

def classify_large_raster(raster_paths, classifier, max_length, tile_size=256, n_jobs=-1):
    """
    Apply a trained Random Forest classifier to multiple rasters using a tiling approach.

    :param raster_paths: List of paths to the raster files (R, G, B).
    :param classifier: Trained RandomForestClassifier.
    :param max_length: The maximum length of the feature vectors as used in training.
    :param tile_size: Size of the tiles to split the raster into. Default is 256.
    :param n_jobs: Number of jobs for parallel processing. Default is -1 (use all processors).
    :return: Classified raster as a 2D numpy array.
    """

    def classify_tile(data, window, max_length, tile_size, classifier):
    
        window_height = min(tile_size, data.shape[1] - window[0])
        window_width = min(tile_size, data.shape[2] - window[1])

        # Initialize an array to hold the classification results
        classified_tile = np.zeros((window_height, window_width), dtype=np.uint8)

        for i in range(window_height):
            for j in range(window_width):
                # Extract the data for the current pixel
                pixel_data = data[:, window[0]+i, window[1]+j]

                # Reshape and prepare pixel data as per the classifier's requirement
                pixel_data_reshaped = reshape_for_prediction(pixel_data, max_length)

                # Predict the class for the current pixel
                prediction = classifier.predict(pixel_data_reshaped.reshape(1, -1))

                # Assign the prediction to the classified tile
                classified_tile[i, j] = prediction

        return classified_tile


    stacked_data, meta = read_and_stack_rasters(raster_paths)

    # Create a list of window positions covering the entire image with specified tile size
    windows = [(row, col) for col in range(0, meta['width'], tile_size) 
               for row in range(0, meta['height'], tile_size)]

    # Use parallel processing to classify each tile
    classified_tiles = Parallel(n_jobs=n_jobs)(
        delayed(classify_tile)(stacked_data, window, max_length, tile_size, classifier) for window in windows)

    # Stitch the classified tiles back together
    classified_raster = np.zeros((meta['height'], meta['width']), dtype=np.uint8)
    for idx, (row_start, col_start) in enumerate(windows):
        row_end = min(row_start + tile_size, meta['height'])
        col_end = min(col_start + tile_size, meta['width'])
        tile_size_y, tile_size_x = classified_tiles[idx].shape
        classified_raster[row_start:row_start+tile_size_y, col_start:col_start+tile_size_x] = classified_tiles[idx]

    
    base_dir = os.path.dirname(raster_paths[0])
    output_dir = os.path.join(base_dir, 'RF_Output')
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Save the classified raster
    output_file_path = os.path.join(output_dir, 'classified_raster.tif')
    with rasterio.open(output_file_path, 'w', **meta) as dst:
        dst.write(classified_raster, 1)

    return classified_raster


# List of raster file paths
raster_paths = [r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Input_Layers\R.tif",
r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Input_Layers\G.tif",
r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Input_Layers\B.tif"]

# Read rasters and shapefile
rasters = [read_raster(path) for path in raster_paths]
shapefile = r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\VEG_BE_KEY.shp"


test_rasters = [r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Test_v1\R.tif",
r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Test_v1\G.tif",
r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Test_v1\B.tif"]

# Extract features and raster outputs
best_model, best_score, performance_metrics, max_length = train_RF(raster_paths, shapefile)

new_raster_predictions = classify_large_raster(raster_paths, best_model, max_length)

print(f"New raster predictions: {new_raster_predictions}")

print(f"Best model parameters: {best_model.get_params()}")
print(f"Best model accuracy: {best_score}")
print(f"Best model performance metrics: {performance_metrics}")
print(f"New raster predictions: {new_raster_predictions}")

