import rasterio
from rasterio.windows import Window
from rasterio.mask import mask
import geopandas as gpd

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder

import numpy as np
import os
from osgeo import gdal
from joblib import Parallel, delayed


def read_raster(file_path):
    # Open the raster file and return the DatasetReader object and its transform
    src = rasterio.open(file_path)
    return src, src.transform

def extract_features(rasters, shapefile):
    features = []
    labels = []
    raster_outputs = []

    for src, transform in rasters:
        raster = src.read()  # Read the raster data as a NumPy array here
        for index, row in shapefile.iterrows():
            out_image, out_transform = mask(src, [row['geometry']], crop=True)
            out_image = out_image.reshape(-1)
            features.append(out_image)
            labels.append(row['MC'])
            raster_outputs.append(out_image)

    # Close each raster file after processing
    for src, _ in rasters:
        src.close()

    return features, labels, raster_outputs

def train_RF(raster_paths, shapefile_path):
    # Read rasters and shapefile
    rasters = [read_raster(path) for path in raster_paths]
    shapefile = gpd.read_file(shapefile_path)

    # Extract features and raster outputs
    features, labels, _ = extract_features(rasters, shapefile)

    # Data Preparation
    # Reshape features
    max_length = max([len(feature) for feature in features])
    features = [np.pad(feature, (0, max_length - len(feature))) if len(feature) < max_length else feature[:max_length] for feature in features]

    # Encode labels
    label_encoder = LabelEncoder()
    encoded_labels = label_encoder.fit_transform(labels)

    # Split Data
    X_train, X_test, y_train, y_test = train_test_split(features, encoded_labels, test_size=0.2, random_state=42)

    # Random Forest Training
    parameter_distributions = {
        'n_estimators': [100, 200, 300, 400, 500],
        'max_depth': [None, 10, 20, 30, 40, 50],
        'min_samples_split': [2, 5, 10, 20],
        'min_samples_leaf': [1, 2, 4, 10]
    }

    rf = RandomForestClassifier(random_state=42)
    random_search = RandomizedSearchCV(estimator=rf, param_distributions=parameter_distributions, 
                                       n_iter=30, cv=4, n_jobs=-1, verbose=2, random_state=42)
    random_search.fit(X_train, y_train)

    # Model Evaluation
    predictions = random_search.predict(X_test)
    print(classification_report(y_test, predictions))

    # Output the best parameters and performance metrics
    best_estimator = random_search.best_estimator_
    best_score = random_search.best_score_
    performance_metrics = random_search.cv_results_

    print("Best Estimator:", best_estimator)
    print("Best Score:", best_score)

    return best_estimator, best_score, performance_metrics

def classify_large_raster(raster_paths, model, window_size=1):
    """
    Classify a large raster using the provided Random Forest model and save output in 'RF_Output' folder.

    Parameters:
    raster_paths (list of str): List of file paths to the raster files.
    model (RandomForestClassifier): Trained Random Forest model.
    window_size (int): Size of the window to process at a time. Default is 1 (each pixel).
    """
    # Determine the base folder from the first raster path
    base_folder = os.path.dirname(raster_paths[0])
    output_folder = os.path.join(base_folder, 'RF_Output')

    # Create the output folder if it doesn't exist
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Output file path
    output_file = os.path.join(output_folder, 'classified_output.tif')

    # Open the first raster to get the metadata and initialize the result array
    with rasterio.open(raster_paths[0]) as src:
        meta = src.meta.copy()
        result = np.zeros((src.height, src.width), dtype=int)

    # Iterate over the raster in windows
    for i in range(0, meta['height'], window_size):
        for j in range(0, meta['width'], window_size):
            window_data = []
            for path in raster_paths:
                with rasterio.open(path) as src:
                    # Define the window
                    window = Window(j, i, window_size, window_size)
                    # Read data from the window and flatten
                    data = src.read(window=window).flatten()
                    window_data.extend(data)

            # Reshape window_data for prediction
            window_data = np.array(window_data).reshape(1, -1)

            # Check if the window_data has the same number of features as the model expects
            if window_data.shape[1] == model.n_features_in_:
                prediction = model.predict(window_data)
                # Assign prediction to result raster
                result[i:i+window_size, j:j+window_size] = prediction.reshape(window_size, window_size)
            else:
                # Handle windows that do not match the model's expected feature size
                # e.g., by assigning a default class or skipping them
                pass

    # Update metadata for the result raster
    meta.update({'count': 1})

    # Write result to a new raster file in the 'RF_Output' folder
    with rasterio.open(output_file, 'w', **meta) as dst:
        dst.write(result, 1)

    return output_file

# Usage Example



# List of raster file paths
raster_paths = [r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Input_Layers\R.tif",
r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Input_Layers\G.tif",
r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\Input_Layers\B.tif"]

# Read rasters and shapefile
rasters = [read_raster(path) for path in raster_paths]
shapefile = r"Z:\ATD\Drone Data Processing\GIS Processing\Vegetation Filtering Test\Test_Train_Set\VEG_BE_KEY.shp"



# Extract features and raster outputs
best_model, best_score, performance_metrics = train_RF(raster_paths, shapefile)

new_raster_predictions = classify_large_raster(raster_paths, best_model)
print(f"New raster predictions: {new_raster_predictions}")

print(f"Best model parameters: {best_model.get_params()}")
print(f"Best model accuracy: {best_score}")
print(f"Best model performance metrics: {performance_metrics}")
print(f"New raster predictions: {new_raster_predictions}")

